{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZzo09YDyY9UzHUQItcblT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnuragSingh7292/Remote-sensing-image-retrieval-deep-learning-/blob/main/ResNetModel%26CombineFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga4lVEXRDHKD",
        "outputId": "9c6f985b-da56-4ea6-8be8-0a0c563baac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# After running, follow the authentication steps\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the paths\n",
        "zip_path = \"/content/drive/MyDrive/Images.zip\"  # Update with your actual file path\n",
        "extract_path = \"/content/UC_Merced_LandUse\"  # Temporary extraction path\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Verify extraction\n",
        "print(\"Extracted categories:\", os.listdir(extract_path))  # Should list 21 folders\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT8w17dwDPfG",
        "outputId": "17dd3b65-84c7-4f5b-abc3-052aa6f70fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted categories: ['Images']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50"
      ],
      "metadata": {
        "id": "luiKRcQoGIsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/UC_Merced_LandUse/Images\"\n",
        "save_dir = \"/content/drive/MyDrive/NewONeFeature_IFK_Vectors\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load ResNet50 model with pre-trained weights\n",
        "base_model = ResNet50(weights='imagenet', include_top=True)\n",
        "\n",
        "# Extracting features from 'conv5_block3_out' (Last convolutional block)\n",
        "conv5_layer = tf.keras.Model(inputs=base_model.input,\n",
        "                             outputs=base_model.get_layer('conv5_block3_out').output)\n",
        "\n",
        "# Extracting features from 'avg_pool' (Instead of FC6, since ResNet50 does not have fully connected layers)\n",
        "fc6_layer = tf.keras.Model(inputs=base_model.input,\n",
        "                           outputs=base_model.get_layer('avg_pool').output)\n",
        "\n",
        "# Function to extract features\n",
        "def extract_features(model, img_path, target_size=(224, 224)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    features = model.predict(img_array, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "# Storage lists\n",
        "conv5_features, fc6_features, labels = [], [], []\n",
        "\n",
        "# Read images and extract features\n",
        "categories = sorted(os.listdir(dataset_path))\n",
        "for idx, category in enumerate(categories):\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        for img_file in os.listdir(category_path):\n",
        "            if img_file.lower().endswith(('.jpg', '.png', '.tif')):\n",
        "                img_path = os.path.join(category_path, img_file)\n",
        "                conv5_feat = extract_features(conv5_layer, img_path)\n",
        "                fc6_feat = extract_features(fc6_layer, img_path)\n",
        "                conv5_features.append(conv5_feat)\n",
        "                fc6_features.append(fc6_feat)\n",
        "                labels.append(idx)\n",
        "\n",
        "# Convert lists to arrays\n",
        "conv5_features = np.array(conv5_features)\n",
        "fc6_features = np.array(fc6_features)\n",
        "\n",
        "# Apply PCA to reduce dimensions to (2100, 32)\n",
        "pca_conv5 = PCA(n_components=32)\n",
        "conv5_reduced = pca_conv5.fit_transform(conv5_features)\n",
        "\n",
        "pca_fc6 = PCA(n_components=32)\n",
        "fc6_reduced = pca_fc6.fit_transform(fc6_features)\n",
        "\n",
        "# Save features as separate .npy files\n",
        "np.save(os.path.join(save_dir, \"resnet50_conv5_32_features.npy\"), conv5_reduced)\n",
        "np.save(os.path.join(save_dir, \"resnet50_fc6_32_features.npy\"), fc6_reduced)\n",
        "np.save(os.path.join(save_dir, \"labels.npy\"), labels)\n",
        "\n",
        "print(\"✅ Features extracted and saved successfully for ResNet50! (Shape: (2100, 32))\")\n"
      ],
      "metadata": {
        "id": "l3BJq30iGEzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet101"
      ],
      "metadata": {
        "id": "p5aHOFtrGNs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/UC_Merced_LandUse/Images\"\n",
        "save_dir = \"/content/drive/MyDrive/NewONeFeature_IFK_Vectors\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load ResNet101 model with pre-trained weights\n",
        "base_model_101 = ResNet101(weights='imagenet', include_top=True)\n",
        "\n",
        "# Extracting features from 'conv5_block3_out' (Last convolutional block)\n",
        "conv5_layer_101 = tf.keras.Model(inputs=base_model_101.input,\n",
        "                                 outputs=base_model_101.get_layer('conv5_block3_out').output)\n",
        "\n",
        "# Extracting features from 'avg_pool'\n",
        "fc6_layer_101 = tf.keras.Model(inputs=base_model_101.input,\n",
        "                               outputs=base_model_101.get_layer('avg_pool').output)\n",
        "\n",
        "# Function to extract features\n",
        "def extract_features(model, img_path, target_size=(224, 224)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    features = model.predict(img_array, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "# Storage lists\n",
        "conv5_features_101, fc6_features_101, labels = [], [], []\n",
        "\n",
        "# Read images and extract features\n",
        "categories = sorted(os.listdir(dataset_path))\n",
        "for idx, category in enumerate(categories):\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        for img_file in os.listdir(category_path):\n",
        "            if img_file.lower().endswith(('.jpg', '.png', '.tif')):\n",
        "                img_path = os.path.join(category_path, img_file)\n",
        "                conv5_feat = extract_features(conv5_layer_101, img_path)\n",
        "                fc6_feat = extract_features(fc6_layer_101, img_path)\n",
        "                conv5_features_101.append(conv5_feat)\n",
        "                fc6_features_101.append(fc6_feat)\n",
        "                labels.append(idx)\n",
        "\n",
        "# Convert lists to arrays\n",
        "conv5_features_101 = np.array(conv5_features_101)\n",
        "fc6_features_101 = np.array(fc6_features_101)\n",
        "\n",
        "# Save features as separate .npy files\n",
        "np.save(os.path.join(save_dir, \"resnet101_conv5_con5_features.npy\"), conv5_features_101)\n",
        "np.save(os.path.join(save_dir, \"resnet101_fc6_fc6_features.npy\"),fc6_features_101)\n",
        "\n",
        "# Apply PCA to reduce dimensions to (2100, 32)\n",
        "pca_conv5_101 = PCA(n_components=32)\n",
        "conv5_reduced_101 = pca_conv5_101.fit_transform(conv5_features_101)\n",
        "\n",
        "pca_fc6_101 = PCA(n_components=32)\n",
        "fc6_reduced_101 = pca_fc6_101.fit_transform(fc6_features_101)\n",
        "\n",
        "# Save features as separate .npy files\n",
        "np.save(os.path.join(save_dir, \"resnet101_conv5_32_features.npy\"), conv5_reduced_101)\n",
        "np.save(os.path.join(save_dir, \"resnet101_fc6_32_features.npy\"), fc6_reduced_101)\n",
        "np.save(os.path.join(save_dir, \"labels.npy\"), labels)\n",
        "\n",
        "print(\"✅ Features extracted and saved successfully for ResNet101! (Shape: (2100, 32))\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq3wtIQVGFy1",
        "outputId": "fbe0db15-7d43-4a95-f10d-ff528169ac57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m179648224/179648224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "✅ Features extracted and saved successfully for ResNet101! (Shape: (2100, 32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conv5_features_101.shape)\n",
        "print(fc6_features_101.shape)\n",
        "print(conv5_reduced_101.shape)\n",
        "print(fc6_reduced_101.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qObmvRxCKApY",
        "outputId": "b128641e-417b-4018-904b-8ba0c2c6a02e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2100, 100352)\n",
            "(2100, 2048)\n",
            "(2100, 32)\n",
            "(2100, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet152"
      ],
      "metadata": {
        "id": "f3IT3Ipy8gXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/UC_Merced_LandUse/Images\"\n",
        "save_dir = \"/content/drive/MyDrive/NewONeFeature_IFK_Vectors\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load ResNet152 model with pre-trained weights\n",
        "base_model_152 = ResNet152(weights='imagenet', include_top=True)\n",
        "\n",
        "# Extracting features from 'avg_pool'\n",
        "fc6_layer_152 = tf.keras.Model(inputs=base_model_152.input,\n",
        "                               outputs=base_model_152.get_layer('avg_pool').output)\n",
        "\n",
        "# Function to extract features\n",
        "def extract_features(model, img_path, target_size=(224, 224)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    features = model.predict(img_array, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "# Storage lists\n",
        "fc6_features_152, labels = [], []\n",
        "\n",
        "# Read images and extract features\n",
        "categories = sorted(os.listdir(dataset_path))\n",
        "for idx, category in enumerate(categories):\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        for img_file in os.listdir(category_path):\n",
        "            if img_file.lower().endswith(('.jpg', '.png', '.tif')):\n",
        "                img_path = os.path.join(category_path, img_file)\n",
        "                fc6_feat = extract_features(fc6_layer_152, img_path)\n",
        "                fc6_features_152.append(fc6_feat)\n",
        "                labels.append(idx)\n",
        "\n",
        "# Convert lists to arrays\n",
        "fc6_features_152 = np.array(fc6_features_152)\n",
        "\n",
        "# Save raw extracted features\n",
        "np.save(os.path.join(save_dir, \"resnet152_fc6_fc6_features.npy\"), fc6_features_152)\n",
        "\n",
        "# Apply PCA to reduce dimensions to (2100, 32)\n",
        "pca_fc6_152 = PCA(n_components=32)\n",
        "fc6_reduced_152 = pca_fc6_152.fit_transform(fc6_features_152)\n",
        "\n",
        "# Save reduced features\n",
        "np.save(os.path.join(save_dir, \"resnet152_fc6_32_features.npy\"), fc6_reduced_152)\n",
        "np.save(os.path.join(save_dir, \"labels.npy\"), labels)\n",
        "\n",
        "print(\"✅ Features extracted and saved successfully for ResNet152! (Shape: (2100, 32))\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "xWakXkW28Z4d",
        "outputId": "413a3c39-94a8-44b9-e6e8-38f992425a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6a3a2fc9ffbd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet152\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/__internal__/feature_column/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDenseColumn\u001b[0m \u001b[0;31m# line: 1777\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureTransformationCache\u001b[0m \u001b[0;31m# line: 1962\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceDenseColumn\u001b[0m \u001b[0;31m# line: 1941\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfc_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_v2_types\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfc_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# =============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mInputSpec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAddMetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_arrays_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_distributed_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_eager_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0missparse\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0missparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from ._sputils import (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[0m\u001b[1;32m      6\u001b[0m                        \u001b[0mget_sum_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                        matrix, validateaxis,)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_sputils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_ulong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxp_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_api_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m from scipy._lib.array_api_compat import (\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mis_array_api_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from numpy import * doesn't overwrite these builtin names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmatlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"f2py\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf2py\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf2py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf2py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"typing\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf2py2e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiagnose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/f2py2e.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrackfortran\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcb_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauxfuncs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcapi_maps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfuncs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcommon_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/f2py/capi_maps.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcrackfortran\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmarkoutercomma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcb_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_isocbind\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miso_c_binding_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misoc_c2pycode_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miso_c2py_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# The environment provided by auxfuncs.py is needed for some calls to eval.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load saved features\n",
        "save_dir = \"/content/drive/MyDrive/NewONeFeature_IFK_Vectors\"\n",
        "\n",
        "resnet50_conv5 = np.load(os.path.join(save_dir, \"resnet50_conv5_32_features.npy\"))\n",
        "resnet50_fc6 = np.load(os.path.join(save_dir, \"resnet50_fc6_32_features.npy\"))\n",
        "\n",
        "resnet101_conv5 = np.load(os.path.join(save_dir, \"resnet101_conv5_32_features.npy\"))\n",
        "resnet101_fc6 = np.load(os.path.join(save_dir, \"resnet101_fc6_32_features.npy\"))\n",
        "\n",
        "labels = np.load(os.path.join(save_dir, \"labels.npy\"))\n",
        "\n",
        "# Feature Fusion (Concatenation)\n",
        "final_features_conv5 = np.concatenate((resnet50_conv5, resnet101_conv5), axis=1)  # Shape: (2100, 64)\n",
        "final_features_fc6 = np.concatenate((resnet50_fc6, resnet101_fc6), axis=1)  # Shape: (2100, 64)\n",
        "\n",
        "# Save the combined features\n",
        "np.save(os.path.join(save_dir, \"combined_conv5_features.npy\"), final_features_conv5)\n",
        "np.save(os.path.join(save_dir, \"combined_fc6_features.npy\"), final_features_fc6)\n",
        "\n",
        "print(\"✅ Combined features saved successfully! (Shape: (2100, 64))\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBVsU1h7K0Dd",
        "outputId": "d1cb4802-5db8-4c83-f4c2-23f57158bf08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Combined features saved successfully! (Shape: (2100, 64))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_features_conv5.shape)\n",
        "print(final_features_fc6.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puc3AvbNLfcc",
        "outputId": "5f1023aa-becc-4a2d-d81e-9642ecf2c893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2100, 64)\n",
            "(2100, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load extracted features and labels for VGG16\n",
        "save_dir = \"/content/drive/MyDrive/NewONeFeature_IFK_Vectors\"\n",
        "features = np.load(f\"{save_dir}/combined_fc6_features.npy\")\n",
        "labels = np.load(f\"{save_dir}/labels.npy\")\n",
        "\n",
        "# Compute Mean Average Precision (MAP)\n",
        "def compute_map(features, labels):\n",
        "    num_images = features.shape[0]\n",
        "    similarity_matrix = cosine_similarity(features)  # Compute cosine similarity\n",
        "    average_precisions = []\n",
        "\n",
        "    for i in range(num_images):\n",
        "        query_label = labels[i]\n",
        "        similarities = similarity_matrix[i]\n",
        "\n",
        "        # Sort images by similarity (descending order) and exclude self-match\n",
        "        sorted_indices = np.argsort(-similarities)\n",
        "        sorted_indices = sorted_indices[sorted_indices != i]  # Remove self-\n",
        "        # sorted_indices = np.delete(sorted_indices, np.where(sorted_indices == i))  # More robust\n",
        "        sorted_labels = labels[sorted_indices]\n",
        "\n",
        "        # Compute relevance scores (1 if label matches, else 0)\n",
        "        relevant_items = (sorted_labels == query_label).astype(int)\n",
        "        num_relevant = np.sum(relevant_items)\n",
        "\n",
        "        # If no relevant items exist, AP is 0\n",
        "        if num_relevant == 0:\n",
        "            average_precisions.append(0)\n",
        "            continue\n",
        "\n",
        "        # Compute precision at each rank\n",
        "        cumulative_relevance = np.cumsum(relevant_items)\n",
        "        precision_at_k = cumulative_relevance / (np.arange(len(relevant_items)) + 1)\n",
        "\n",
        "        # Compute Average Precision (AP)\n",
        "        average_precision = np.sum(precision_at_k * relevant_items) / num_relevant\n",
        "        average_precisions.append(average_precision)\n",
        "\n",
        "    # Compute Mean Average Precision (MAP)\n",
        "    mean_average_precision = np.mean(average_precisions)\n",
        "    return mean_average_precision\n",
        "\n",
        "# Compute and print MAP for VGG16\n",
        "map_score = compute_map(features, labels)\n",
        "print(f\"✅ MAP for combine ResNet 50&101 : {map_score * 100:.2f}%\")  # Convert to percentage\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyeSN9rALfbm",
        "outputId": "cb02771f-bbff-4000-8585-bceb99cb4138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MAP for combine ResNet 50&101 : 71.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANMRR"
      ],
      "metadata": {
        "id": "qYBb3ThiOblh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "def compute_anmrr(labels, distance_matrix):\n",
        "    num_images = len(labels)\n",
        "    anmrr_values = []\n",
        "\n",
        "    for i in range(num_images):\n",
        "        # Sort indices based on distance (ascending order)\n",
        "        sorted_indices = np.argsort(distance_matrix[i])\n",
        "        sorted_indices = sorted_indices[sorted_indices != i]  # Exclude self-match\n",
        "\n",
        "        # Retrieve the sorted labels\n",
        "        sorted_labels = labels[sorted_indices]\n",
        "\n",
        "        # Identify relevant items\n",
        "        relevant_items = (sorted_labels == labels[i])\n",
        "        num_relevant = np.sum(relevant_items)\n",
        "\n",
        "        if num_relevant == 0:\n",
        "            anmrr_values.append(1)  # Worst case if no relevant images found\n",
        "            continue\n",
        "\n",
        "        # Compute rank positions of relevant items\n",
        "        rank_positions = np.where(relevant_items)[0] + 1  # Convert to 1-based indexing\n",
        "\n",
        "        # Compute Modified Retrieval Rank (MRR)\n",
        "        mrr = np.sum(rank_positions) / num_relevant\n",
        "\n",
        "        # Compute Normalized Modified Retrieval Rank (NMRR)\n",
        "        # K = min(2 * num_relevant, num_images)  # Dynamic cut-off based on relevant items\n",
        "        K = num_images  # Since we are considering all images\n",
        "        nmrr = (mrr - 0.5 * (1 + num_relevant)) / (1.25 * K - 0.5 * (1 + num_relevant))\n",
        "\n",
        "        anmrr_values.append(nmrr)\n",
        "\n",
        "    # Mean of NMRR values\n",
        "    anmrr = np.mean(anmrr_values)\n",
        "    return anmrr\n",
        "\n",
        "\n",
        "# Compute and print ANMRR for each model (all images)\n",
        "\n",
        "features = np.load(f\"/content/drive/MyDrive/NewONeFeature_IFK_Vectors/combined_fc6_features.npy\")\n",
        "labels = np.load(f\"/content/drive/MyDrive/NewONeFeature_IFK_Vectors/labels.npy\")\n",
        "\n",
        "# Compute distance matrix efficiently using cdist (Euclidean distance)\n",
        "distance_matrix = cdist(features, features, metric='euclidean')\n",
        "\n",
        "# Compute ANMRR for all images\n",
        "anmrr_score = compute_anmrr(labels, distance_matrix)\n",
        "print(f\"ANMRR for combine  ResNet 50&101: {anmrr_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7daa6d5c-da9c-499f-e3f9-b5a1afe01aa2",
        "id": "lThUOndpP19w"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANMRR for combine  ResNet 50&101: 0.0370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WkfKkEWtJgeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load concatenated features (64 dimensions)\n",
        "save_dir = \"/content/drive/MyDrive/NewONeFeature_IFK_Vectors\"\n",
        "combined_features = np.load(f\"{save_dir}/combined_fc6_features.npy\")  # Shape: (2100, 64)\n",
        "\n",
        "# Apply PCA to reduce to 32 dimensions\n",
        "pca = PCA(n_components=32)\n",
        "combined_features_32 = pca.fit_transform(combined_features)\n",
        "\n",
        "# Save the new 32-dimensional features\n",
        "np.save(f\"{save_dir}/combined_fc6_32_features.npy\", combined_features_32)\n",
        "\n",
        "print(f\"✅ Combined features reduced to 32 dimensions! New shape: {combined_features_32.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF97-KHkUGfx",
        "outputId": "4631de9f-a530-416b-b4b7-60f709e7a74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Combined features reduced to 32 dimensions! New shape: (2100, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_features_32.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTw2BRZnUJHF",
        "outputId": "4bfd23fb-1eee-413c-dfe7-0b1facbf6078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2100, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAP 32"
      ],
      "metadata": {
        "id": "GoZst_C6UQUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load extracted features and labels for VGG16\n",
        "save_dir = \"/content/drive/MyDrive/NewONeFeature_IFK_Vectors\"\n",
        "features = np.load(f\"{save_dir}/combined_fc6_32_features.npy\")\n",
        "labels = np.load(f\"{save_dir}/labels.npy\")\n",
        "\n",
        "# Compute Mean Average Precision (MAP)\n",
        "def compute_map(features, labels):\n",
        "    num_images = features.shape[0]\n",
        "    similarity_matrix = cosine_similarity(features)  # Compute cosine similarity\n",
        "    average_precisions = []\n",
        "\n",
        "    for i in range(num_images):\n",
        "        query_label = labels[i]\n",
        "        similarities = similarity_matrix[i]\n",
        "\n",
        "        # Sort images by similarity (descending order) and exclude self-match\n",
        "        sorted_indices = np.argsort(-similarities)\n",
        "        sorted_indices = sorted_indices[sorted_indices != i]  # Remove self-\n",
        "        # sorted_indices = np.delete(sorted_indices, np.where(sorted_indices == i))  # More robust\n",
        "        sorted_labels = labels[sorted_indices]\n",
        "\n",
        "        # Compute relevance scores (1 if label matches, else 0)\n",
        "        relevant_items = (sorted_labels == query_label).astype(int)\n",
        "        num_relevant = np.sum(relevant_items)\n",
        "\n",
        "        # If no relevant items exist, AP is 0\n",
        "        if num_relevant == 0:\n",
        "            average_precisions.append(0)\n",
        "            continue\n",
        "\n",
        "        # Compute precision at each rank\n",
        "        cumulative_relevance = np.cumsum(relevant_items)\n",
        "        precision_at_k = cumulative_relevance / (np.arange(len(relevant_items)) + 1)\n",
        "\n",
        "        # Compute Average Precision (AP)\n",
        "        average_precision = np.sum(precision_at_k * relevant_items) / num_relevant\n",
        "        average_precisions.append(average_precision)\n",
        "\n",
        "    # Compute Mean Average Precision (MAP)\n",
        "    mean_average_precision = np.mean(average_precisions)\n",
        "    return mean_average_precision\n",
        "\n",
        "# Compute and print MAP for VGG16\n",
        "map_score = compute_map(features, labels)\n",
        "print(f\"✅ MAP for combine ResNet 50&101 : {map_score * 100:.2f}%\")  # Convert to percentage\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDH8SoDNUMLv",
        "outputId": "67e8544d-7c47-4c21-84f2-951ec1eb16c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MAP for combine ResNet 50&101 : 72.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANMRR 32"
      ],
      "metadata": {
        "id": "FvhkGB-DUd5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "def compute_anmrr(labels, distance_matrix):\n",
        "    num_images = len(labels)\n",
        "    anmrr_values = []\n",
        "\n",
        "    for i in range(num_images):\n",
        "        # Sort indices based on distance (ascending order)\n",
        "        sorted_indices = np.argsort(distance_matrix[i])\n",
        "        sorted_indices = sorted_indices[sorted_indices != i]  # Exclude self-match\n",
        "\n",
        "        # Retrieve the sorted labels\n",
        "        sorted_labels = labels[sorted_indices]\n",
        "\n",
        "        # Identify relevant items\n",
        "        relevant_items = (sorted_labels == labels[i])\n",
        "        num_relevant = np.sum(relevant_items)\n",
        "\n",
        "        if num_relevant == 0:\n",
        "            anmrr_values.append(1)  # Worst case if no relevant images found\n",
        "            continue\n",
        "\n",
        "        # Compute rank positions of relevant items\n",
        "        rank_positions = np.where(relevant_items)[0] + 1  # Convert to 1-based indexing\n",
        "\n",
        "        # Compute Modified Retrieval Rank (MRR)\n",
        "        mrr = np.sum(rank_positions) / num_relevant\n",
        "\n",
        "        # Compute Normalized Modified Retrieval Rank (NMRR)\n",
        "        # K = min(2 * num_relevant, num_images)  # Dynamic cut-off based on relevant items\n",
        "        K = num_images  # Since we are considering all images\n",
        "        nmrr = (mrr - 0.5 * (1 + num_relevant)) / (1.25 * K - 0.5 * (1 + num_relevant))\n",
        "\n",
        "        anmrr_values.append(nmrr)\n",
        "\n",
        "    # Mean of NMRR values\n",
        "    anmrr = np.mean(anmrr_values)\n",
        "    return anmrr\n",
        "\n",
        "\n",
        "# Compute and print ANMRR for each model (all images)\n",
        "\n",
        "features = np.load(f\"/content/drive/MyDrive/NewONeFeature_IFK_Vectors/combined_fc6_32_features.npy\")\n",
        "labels = np.load(f\"/content/drive/MyDrive/NewONeFeature_IFK_Vectors/labels.npy\")\n",
        "\n",
        "# Compute distance matrix efficiently using cdist (Euclidean distance)\n",
        "distance_matrix = cdist(features, features, metric='euclidean')\n",
        "\n",
        "# Compute ANMRR for all images\n",
        "anmrr_score = compute_anmrr(labels, distance_matrix)\n",
        "print(f\"ANMRR for combine  ResNet 50&101 : {anmrr_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk2_S6InUfwb",
        "outputId": "1e48d712-6e05-4c0b-ec99-77da52ee6d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANMRR for combine  ResNet 50&101 : 0.0310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "clahe code on ResNet 101"
      ],
      "metadata": {
        "id": "b8hndxYrgKL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/UC_Merced_LandUse/Images\"\n",
        "save_dir = \"/content/drive/MyDrive/NewONeFeature_IFK_Vectors\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load ResNet101 model with pre-trained weights\n",
        "base_model_101 = ResNet101(weights='imagenet', include_top=True)\n",
        "\n",
        "# Extracting features from 'conv5_block3_out' (Last convolutional block)\n",
        "conv5_layer_101 = tf.keras.Model(inputs=base_model_101.input,\n",
        "                                 outputs=base_model_101.get_layer('conv5_block3_out').output)\n",
        "\n",
        "# Extracting features from 'avg_pool'\n",
        "fc6_layer_101 = tf.keras.Model(inputs=base_model_101.input,\n",
        "                               outputs=base_model_101.get_layer('avg_pool').output)\n",
        "\n",
        "# Function to Apply CLAHE\n",
        "def apply_clahe(img):\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)  # Convert to LAB space\n",
        "    l, a, b = cv2.split(lab)  # Split channels\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))  # CLAHE on L channel\n",
        "    l_clahe = clahe.apply(l)\n",
        "    lab_clahe = cv2.merge((l_clahe, a, b))  # Merge back\n",
        "    return cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)  # Convert back to BGR\n",
        "\n",
        "# Function to Extract Features\n",
        "def extract_features(model, img_path, target_size=(224, 224)):\n",
        "    img = cv2.imread(img_path)  # Read image\n",
        "    img = cv2.resize(img, target_size)  # Resize to model input size\n",
        "    img = apply_clahe(img)  # Apply CLAHE preprocessing\n",
        "\n",
        "    # Convert to Keras-compatible format\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    # Extract Features\n",
        "    features = model.predict(img_array, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "# Storage lists\n",
        "conv5_features_101, fc6_features_101, labels = [], [], []\n",
        "\n",
        "# Read images and extract features\n",
        "categories = sorted(os.listdir(dataset_path))\n",
        "for idx, category in enumerate(categories):\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        for img_file in os.listdir(category_path):\n",
        "            if img_file.lower().endswith(('.jpg', '.png', '.tif')):\n",
        "                img_path = os.path.join(category_path, img_file)\n",
        "                conv5_feat = extract_features(conv5_layer_101, img_path)\n",
        "                fc6_feat = extract_features(fc6_layer_101, img_path)\n",
        "                conv5_features_101.append(conv5_feat)\n",
        "                fc6_features_101.append(fc6_feat)\n",
        "                labels.append(idx)\n",
        "\n",
        "# Convert lists to arrays\n",
        "conv5_features_101 = np.array(conv5_features_101)\n",
        "fc6_features_101 = np.array(fc6_features_101)\n",
        "\n",
        "# Save full-dimension features\n",
        "np.save(os.path.join(save_dir, \"resnet101_conv5_clahe_features.npy\"), conv5_features_101)\n",
        "np.save(os.path.join(save_dir, \"resnet101_fc6_clahe_features.npy\"), fc6_features_101)\n",
        "\n",
        "# Apply PCA to reduce dimensions to (2100, 32)\n",
        "pca_conv5_101 = PCA(n_components=32)\n",
        "conv5_reduced_101 = pca_conv5_101.fit_transform(conv5_features_101)\n",
        "\n",
        "pca_fc6_101 = PCA(n_components=32)\n",
        "fc6_reduced_101 = pca_fc6_101.fit_transform(fc6_features_101)\n",
        "\n",
        "# Save PCA-reduced features\n",
        "np.save(os.path.join(save_dir, \"resnet101_conv5_32_clahe_features.npy\"), conv5_reduced_101)\n",
        "np.save(os.path.join(save_dir, \"resnet101_fc6_32_clahe_features.npy\"), fc6_reduced_101)\n",
        "np.save(os.path.join(save_dir, \"labels.npy\"), labels)\n",
        "\n",
        "print(\"✅ Features extracted with CLAHE and saved successfully for ResNet101! (Shape: (2100, 32))\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORB1uREBgLcB",
        "outputId": "f144d972-9bc9-4a7f-b542-03e1d8c69205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Features extracted with CLAHE and saved successfully for ResNet101! (Shape: (2100, 32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50 clahe"
      ],
      "metadata": {
        "id": "DFbtvgFOhsrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/UC_Merced_LandUse/Images\"\n",
        "save_dir = \"/content/drive/MyDrive/NewONeFeature_IFK_Vectors\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load ResNet50 model with pre-trained weights\n",
        "base_model = ResNet50(weights='imagenet', include_top=True)\n",
        "\n",
        "# Extracting features from 'conv5_block3_out' (Last convolutional block)\n",
        "conv5_layer = tf.keras.Model(inputs=base_model.input,\n",
        "                             outputs=base_model.get_layer('conv5_block3_out').output)\n",
        "\n",
        "# Extracting features from 'avg_pool'\n",
        "fc6_layer = tf.keras.Model(inputs=base_model.input,\n",
        "                           outputs=base_model.get_layer('avg_pool').output)\n",
        "\n",
        "# Function to Apply CLAHE\n",
        "def apply_clahe(img):\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)  # Convert to LAB space\n",
        "    l, a, b = cv2.split(lab)  # Split channels\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))  # CLAHE on L channel\n",
        "    l_clahe = clahe.apply(l)\n",
        "    lab_clahe = cv2.merge((l_clahe, a, b))  # Merge back\n",
        "    return cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)  # Convert back to BGR\n",
        "\n",
        "# Function to Extract Features\n",
        "def extract_features(model, img_path, target_size=(224, 224)):\n",
        "    img = cv2.imread(img_path)  # Read image\n",
        "    img = cv2.resize(img, target_size)  # Resize to model input size\n",
        "    img = apply_clahe(img)  # Apply CLAHE preprocessing\n",
        "\n",
        "    # Convert to Keras-compatible format\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    # Extract Features\n",
        "    features = model.predict(img_array, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "# Storage lists\n",
        "conv5_features, fc6_features, labels = [], [], []\n",
        "\n",
        "# Read images and extract features\n",
        "categories = sorted(os.listdir(dataset_path))\n",
        "for idx, category in enumerate(categories):\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        for img_file in os.listdir(category_path):\n",
        "            if img_file.lower().endswith(('.jpg', '.png', '.tif')):\n",
        "                img_path = os.path.join(category_path, img_file)\n",
        "                conv5_feat = extract_features(conv5_layer, img_path)\n",
        "                fc6_feat = extract_features(fc6_layer, img_path)\n",
        "                conv5_features.append(conv5_feat)\n",
        "                fc6_features.append(fc6_feat)\n",
        "                labels.append(idx)\n",
        "\n",
        "# Convert lists to arrays\n",
        "conv5_features = np.array(conv5_features)\n",
        "fc6_features = np.array(fc6_features)\n",
        "\n",
        "# Apply PCA to reduce dimensions to (2100, 32)\n",
        "pca_conv5 = PCA(n_components=32)\n",
        "conv5_reduced = pca_conv5.fit_transform(conv5_features)\n",
        "\n",
        "pca_fc6 = PCA(n_components=32)\n",
        "fc6_reduced = pca_fc6.fit_transform(fc6_features)\n",
        "\n",
        "# Save features as separate .npy files\n",
        "np.save(os.path.join(save_dir, \"resnet50_conv5_32_clahe_features.npy\"), conv5_reduced)\n",
        "np.save(os.path.join(save_dir, \"resnet50_fc6_32_clahe_features.npy\"), fc6_reduced)\n",
        "np.save(os.path.join(save_dir, \"labels.npy\"), labels)\n",
        "\n",
        "print(\"✅ Features extracted with CLAHE and saved successfully for ResNet50! (Shape: (2100, 32))\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG6k8hPLhvZy",
        "outputId": "c971e3df-39d9-4e3e-bdd2-58f21f8c5dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "✅ Features extracted with CLAHE and saved successfully for ResNet50! (Shape: (2100, 32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load extracted features and labels for VGG16\n",
        "save_dir = \"/content/drive/MyDrive/NewONeFeature_IFK_Vectors\"\n",
        "# features = np.load(f\"{save_dir}/resnet50_fc6_32_clahe_features.npy\")\n",
        "features = np.load(f\"{save_dir}/resnet101_fc6_32_clahe_features.npy\")\n",
        "\n",
        "labels = np.load(f\"{save_dir}/labels.npy\")\n",
        "\n",
        "# Compute Mean Average Precision (MAP)\n",
        "def compute_map(features, labels):\n",
        "    num_images = features.shape[0]\n",
        "    similarity_matrix = cosine_similarity(features)  # Compute cosine similarity\n",
        "    average_precisions = []\n",
        "\n",
        "    for i in range(num_images):\n",
        "        query_label = labels[i]\n",
        "        similarities = similarity_matrix[i]\n",
        "\n",
        "        # Sort images by similarity (descending order) and exclude self-match\n",
        "        sorted_indices = np.argsort(-similarities)\n",
        "        sorted_indices = sorted_indices[sorted_indices != i]  # Remove self-\n",
        "        # sorted_indices = np.delete(sorted_indices, np.where(sorted_indices == i))  # More robust\n",
        "        sorted_labels = labels[sorted_indices]\n",
        "\n",
        "        # Compute relevance scores (1 if label matches, else 0)\n",
        "        relevant_items = (sorted_labels == query_label).astype(int)\n",
        "        num_relevant = np.sum(relevant_items)\n",
        "\n",
        "        # If no relevant items exist, AP is 0\n",
        "        if num_relevant == 0:\n",
        "            average_precisions.append(0)\n",
        "            continue\n",
        "\n",
        "        # Compute precision at each rank\n",
        "        cumulative_relevance = np.cumsum(relevant_items)\n",
        "        precision_at_k = cumulative_relevance / (np.arange(len(relevant_items)) + 1)\n",
        "\n",
        "        # Compute Average Precision (AP)\n",
        "        average_precision = np.sum(precision_at_k * relevant_items) / num_relevant\n",
        "        average_precisions.append(average_precision)\n",
        "\n",
        "    # Compute Mean Average Precision (MAP)\n",
        "    mean_average_precision = np.mean(average_precisions)\n",
        "    return mean_average_precision\n",
        "\n",
        "# Compute and print MAP for VGG16\n",
        "map_score = compute_map(features, labels)\n",
        "print(f\"✅ MAP for combine ResNet 50&101 : {map_score * 100:.2f}%\")  # Convert to percentage\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEwYGq2gorUR",
        "outputId": "51ca21da-2246-40a7-f024-5a4fcb118b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MAP for combine ResNet 50&101 : 58.93%\n"
          ]
        }
      ]
    }
  ]
}